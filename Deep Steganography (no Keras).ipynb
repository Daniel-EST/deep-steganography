{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KkYV6i61ImJf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zOPx74naImJh"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jodObMFeImJi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9Agih9RaJeX5"
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets --progress-bar off "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XUUZzgSEImJj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ddsantos/miniconda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using custom data configuration Maysee--tiny-imagenet-35af7c46a941f08e\n",
      "Found cached dataset parquet (/Users/ddsantos/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-35af7c46a941f08e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00, 60.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('Maysee/tiny-imagenet')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_cover, train_secret = train_test_split(dataset['train']['image'][:15000], train_size=0.5, shuffle=True)\n",
    "test_cover, test_secret = train_test_split(dataset['valid']['image'][:1000], train_size=0.5, shuffle=True)\n",
    "\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "j7OYmSh4ImJj"
   },
   "outputs": [],
   "source": [
    "STEPS = len(train_cover) // BATCH_SIZE + 1\n",
    "TEST_STEPS = len(test_cover) // BATCH_SIZE + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JxjS0ZCbImJk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ([np.asarray(x.convert('RGB')) for x in train_cover], \n",
    "     [np.asarray(x.convert('RGB')) for x in train_secret])\n",
    ")\n",
    "\n",
    "del train_cover\n",
    "del train_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yypM6p0qImJl"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(64).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eD6ys0Z2ImJl"
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ([np.asarray(x.convert('RGB')) for x in test_cover], \n",
    "     [np.asarray(x.convert('RGB')) for x in test_secret])\n",
    ")\n",
    "\n",
    "del test_cover\n",
    "del test_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mMJrY4I3ImJl"
   },
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IfdnueRnImJm"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def conv2d(input, filters, biases, strides=1):\n",
    "    x = tf.nn.conv2d(input, filters, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, biases)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Quy_4YhLImJm"
   },
   "outputs": [],
   "source": [
    "initializer = tf.initializers.glorot_normal(12541)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-v7LD8UOImJm"
   },
   "outputs": [],
   "source": [
    "WEIGHTS_PREP_NETWORK = {\n",
    "    'conv3x3_1': tf.Variable(initializer([3, 3, 3, 50])),\n",
    "    'conv3x3_2': tf.Variable(initializer([3, 3, 50, 50])),\n",
    "    'conv3x3_3': tf.Variable(initializer([3, 3, 50, 50])),\n",
    "    'conv3x3_4': tf.Variable(initializer([3, 3, 50, 50])),\n",
    "\n",
    "    'conv4x4_1': tf.Variable(initializer([4, 4, 3, 50])),\n",
    "    'conv4x4_2': tf.Variable(initializer([4, 4, 50, 50])),\n",
    "    'conv4x4_3': tf.Variable(initializer([4, 4, 50, 50])),\n",
    "    'conv4x4_4': tf.Variable(initializer([4, 4, 50, 50])),\n",
    "\n",
    "    'conv5x5_1': tf.Variable(initializer([5, 5, 3, 50])),\n",
    "    'conv5x5_2': tf.Variable(initializer([5, 5, 50, 50])),\n",
    "    'conv5x5_3': tf.Variable(initializer([5, 5, 50, 50])),\n",
    "    'conv5x5_4': tf.Variable(initializer([5, 5, 50, 50])),\n",
    "\n",
    "    'conv3x3_5': tf.Variable(initializer([3, 3, 150, 50])),\n",
    "    'conv4x4_5': tf.Variable(initializer([4, 4, 150, 50])),\n",
    "    'conv5x5_5': tf.Variable(initializer([5, 5, 150, 50]))\n",
    "}\n",
    "\n",
    "BIASES_PREP_NETWORK = {\n",
    "    'conv3x3_1': tf.Variable(tf.zeros([50])),\n",
    "    'conv3x3_2': tf.Variable(tf.zeros([50])),\n",
    "    'conv3x3_3': tf.Variable(tf.zeros([50])),\n",
    "    'conv3x3_4': tf.Variable(tf.zeros([50])),\n",
    "    \n",
    "    'conv4x4_1': tf.Variable(tf.zeros([50])),\n",
    "    'conv4x4_2': tf.Variable(tf.zeros([50])),\n",
    "    'conv4x4_3': tf.Variable(tf.zeros([50])),\n",
    "    'conv4x4_4': tf.Variable(tf.zeros([50])),\n",
    "\n",
    "    'conv5x5_1': tf.Variable(tf.zeros([50])),\n",
    "    'conv5x5_2': tf.Variable(tf.zeros([50])),\n",
    "    'conv5x5_3': tf.Variable(tf.zeros([50])),\n",
    "    'conv5x5_4': tf.Variable(tf.zeros([50])),\n",
    "\n",
    "\n",
    "    'conv3x3_5': tf.Variable(tf.zeros([50])),\n",
    "    'conv4x4_5': tf.Variable(tf.zeros([50])),\n",
    "    'conv5x5_5': tf.Variable(tf.zeros([50]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "i2XC6b9XImJn"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def prep_network(secret_tensor):\n",
    "\n",
    "    secret_tensor = tf.reshape(secret_tensor, [-1, 64, 64, 3])\n",
    "    secret_tensor = tf.cast(secret_tensor, tf.float32)\n",
    "    secret_tensor = tf.math.divide(secret_tensor, 255.)\n",
    "\n",
    "    with tf.name_scope('prep_network'):\n",
    "        with tf.name_scope('conv3x3'):\n",
    "            conv3x3 = secret_tensor\n",
    "            conv3x3 = conv2d(conv3x3, WEIGHTS_PREP_NETWORK['conv3x3_1'], BIASES_PREP_NETWORK['conv3x3_1'])\n",
    "            conv3x3 = conv2d(conv3x3, WEIGHTS_PREP_NETWORK['conv3x3_2'], BIASES_PREP_NETWORK['conv3x3_2'])\n",
    "            conv3x3 = conv2d(conv3x3, WEIGHTS_PREP_NETWORK['conv3x3_3'], BIASES_PREP_NETWORK['conv3x3_3'])\n",
    "            conv3x3 = conv2d(conv3x3, WEIGHTS_PREP_NETWORK['conv3x3_4'], BIASES_PREP_NETWORK['conv3x3_4'])\n",
    "\n",
    "        with tf.name_scope('conv4x4'):\n",
    "            conv4x4 = secret_tensor\n",
    "            conv4x4 = conv2d(conv4x4, WEIGHTS_PREP_NETWORK['conv4x4_1'], BIASES_PREP_NETWORK['conv4x4_1'])\n",
    "            conv4x4 = conv2d(conv4x4, WEIGHTS_PREP_NETWORK['conv4x4_2'], BIASES_PREP_NETWORK['conv4x4_2'])\n",
    "            conv4x4 = conv2d(conv4x4, WEIGHTS_PREP_NETWORK['conv4x4_3'], BIASES_PREP_NETWORK['conv4x4_3'])\n",
    "            conv4x4 = conv2d(conv4x4, WEIGHTS_PREP_NETWORK['conv4x4_4'], BIASES_PREP_NETWORK['conv4x4_4'])\n",
    "\n",
    "        with tf.name_scope('conv5x5'):\n",
    "            conv5x5 = secret_tensor\n",
    "            conv5x5 = conv2d(conv5x5, WEIGHTS_PREP_NETWORK['conv5x5_1'], BIASES_PREP_NETWORK['conv5x5_1'])\n",
    "            conv5x5 = conv2d(conv5x5, WEIGHTS_PREP_NETWORK['conv5x5_2'], BIASES_PREP_NETWORK['conv5x5_2'])\n",
    "            conv5x5 = conv2d(conv5x5, WEIGHTS_PREP_NETWORK['conv5x5_3'], BIASES_PREP_NETWORK['conv5x5_3'])\n",
    "            conv5x5 = conv2d(conv5x5, WEIGHTS_PREP_NETWORK['conv5x5_4'], BIASES_PREP_NETWORK['conv5x5_4'])\n",
    "        \n",
    "        concat_1 = tf.concat([conv3x3, conv4x4, conv5x5], axis=3)\n",
    "\n",
    "        conv3x3 = conv2d(concat_1, WEIGHTS_PREP_NETWORK['conv3x3_5'], BIASES_PREP_NETWORK['conv3x3_5'])\n",
    "        conv4x4 = conv2d(concat_1, WEIGHTS_PREP_NETWORK['conv4x4_5'], BIASES_PREP_NETWORK['conv4x4_5'])\n",
    "        conv5x5 = conv2d(concat_1, WEIGHTS_PREP_NETWORK['conv5x5_5'], BIASES_PREP_NETWORK['conv5x5_5'])\n",
    "\n",
    "        return tf.concat([conv3x3, conv4x4, conv5x5], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QD2Bulp5ImJo"
   },
   "outputs": [],
   "source": [
    "WEIGHTS_HIDE_NETWORK = {\n",
    "    'conv3x3_1': tf.Variable(initializer([3, 3, 153, 50])),\n",
    "    'conv3x3_2': tf.Variable(initializer([3, 3, 50, 50])),\n",
    "    'conv3x3_3': tf.Variable(initializer([3, 3, 50, 50])),\n",
    "    'conv3x3_4': tf.Variable(initializer([3, 3, 50, 50])),\n",
    "\n",
    "    'conv4x4_1': tf.Variable(initializer([4, 4, 153, 50])),\n",
    "    'conv4x4_2': tf.Variable(initializer([4, 4, 50, 50])),\n",
    "    'conv4x4_3': tf.Variable(initializer([4, 4, 50, 50])),\n",
    "    'conv4x4_4': tf.Variable(initializer([4, 4, 50, 50])),\n",
    "\n",
    "    'conv5x5_1': tf.Variable(initializer([5, 5, 153, 50])),\n",
    "    'conv5x5_2': tf.Variable(initializer([5, 5, 50, 50])),\n",
    "    'conv5x5_3': tf.Variable(initializer([5, 5, 50, 50])),\n",
    "    'conv5x5_4': tf.Variable(initializer([5, 5, 50, 50])),\n",
    "\n",
    "    'conv3x3_5': tf.Variable(initializer([3, 3, 150, 50])),\n",
    "    'conv4x4_5': tf.Variable(initializer([4, 4, 150, 50])),\n",
    "    'conv5x5_5': tf.Variable(initializer([5, 5, 150, 50])),\n",
    "\n",
    "    'out': tf.Variable(initializer([1, 1, 150, 3])),\n",
    "}\n",
    "\n",
    "BIASES_HIDE_NETWORK = {\n",
    "    'conv3x3_1': tf.Variable(tf.zeros([50])),\n",
    "    'conv3x3_2': tf.Variable(tf.zeros([50])),\n",
    "    'conv3x3_3': tf.Variable(tf.zeros([50])),\n",
    "    'conv3x3_4': tf.Variable(tf.zeros([50])),\n",
    "    \n",
    "    'conv4x4_1': tf.Variable(tf.zeros([50])),\n",
    "    'conv4x4_2': tf.Variable(tf.zeros([50])),\n",
    "    'conv4x4_3': tf.Variable(tf.zeros([50])),\n",
    "    'conv4x4_4': tf.Variable(tf.zeros([50])),\n",
    "\n",
    "    'conv5x5_1': tf.Variable(tf.zeros([50])),\n",
    "    'conv5x5_2': tf.Variable(tf.zeros([50])),\n",
    "    'conv5x5_3': tf.Variable(tf.zeros([50])),\n",
    "    'conv5x5_4': tf.Variable(tf.zeros([50])),\n",
    "\n",
    "\n",
    "    'conv3x3_5': tf.Variable(tf.zeros([50])),\n",
    "    'conv4x4_5': tf.Variable(tf.zeros([50])),\n",
    "    'conv5x5_5': tf.Variable(tf.zeros([50])),\n",
    "    \n",
    "    'out': tf.Variable(tf.zeros([3]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "e9QPA0F4ImJp"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def hide_network(cover_tensor, prep_tensor):\n",
    "\n",
    "    cover_tensor = tf.reshape(cover_tensor, [-1, 64, 64, 3])\n",
    "    cover_tensor = tf.cast(cover_tensor, tf.float32)\n",
    "    cover_tensor = tf.math.divide(cover_tensor, 255.)\n",
    "\n",
    "    with tf.name_scope('hide_network'):\n",
    "        concat_1 = tf.concat([cover_tensor, prep_tensor], axis=3)\n",
    "\n",
    "        with tf.name_scope('conv3x3'):\n",
    "            conv3x3 = concat_1\n",
    "            conv3x3 = conv2d(conv3x3, WEIGHTS_HIDE_NETWORK['conv3x3_1'], BIASES_HIDE_NETWORK['conv3x3_1'])\n",
    "            conv3x3 = conv2d(conv3x3, WEIGHTS_HIDE_NETWORK['conv3x3_2'], BIASES_HIDE_NETWORK['conv3x3_2'])\n",
    "            conv3x3 = conv2d(conv3x3, WEIGHTS_HIDE_NETWORK['conv3x3_3'], BIASES_HIDE_NETWORK['conv3x3_3'])\n",
    "            conv3x3 = conv2d(conv3x3, WEIGHTS_HIDE_NETWORK['conv3x3_4'], BIASES_HIDE_NETWORK['conv3x3_4'])\n",
    "\n",
    "        with tf.name_scope('conv4x4'):\n",
    "            conv4x4 = concat_1\n",
    "            conv4x4 = conv2d(conv4x4, WEIGHTS_HIDE_NETWORK['conv4x4_1'], BIASES_HIDE_NETWORK['conv4x4_1'])\n",
    "            conv4x4 = conv2d(conv4x4, WEIGHTS_HIDE_NETWORK['conv4x4_2'], BIASES_HIDE_NETWORK['conv4x4_2'])\n",
    "            conv4x4 = conv2d(conv4x4, WEIGHTS_HIDE_NETWORK['conv4x4_3'], BIASES_HIDE_NETWORK['conv4x4_3'])\n",
    "            conv4x4 = conv2d(conv4x4, WEIGHTS_HIDE_NETWORK['conv4x4_4'], BIASES_HIDE_NETWORK['conv4x4_4'])\n",
    "\n",
    "        with tf.name_scope('conv5x5'):\n",
    "            conv5x5 = concat_1\n",
    "            conv5x5 = conv2d(conv5x5, WEIGHTS_HIDE_NETWORK['conv5x5_1'], BIASES_HIDE_NETWORK['conv5x5_1'])\n",
    "            conv5x5 = conv2d(conv5x5, WEIGHTS_HIDE_NETWORK['conv5x5_2'], BIASES_HIDE_NETWORK['conv5x5_2'])\n",
    "            conv5x5 = conv2d(conv5x5, WEIGHTS_HIDE_NETWORK['conv5x5_3'], BIASES_HIDE_NETWORK['conv5x5_3'])\n",
    "            conv5x5 = conv2d(conv5x5, WEIGHTS_HIDE_NETWORK['conv5x5_4'], BIASES_HIDE_NETWORK['conv5x5_4'])\n",
    "        \n",
    "        concat_2 = tf.concat([conv3x3, conv4x4, conv5x5], axis=3)\n",
    "\n",
    "        conv3x3 = conv2d(concat_2, WEIGHTS_HIDE_NETWORK['conv3x3_5'], BIASES_HIDE_NETWORK['conv3x3_5'])\n",
    "        conv4x4 = conv2d(concat_2, WEIGHTS_HIDE_NETWORK['conv4x4_5'], BIASES_HIDE_NETWORK['conv4x4_5'])\n",
    "        conv5x5 = conv2d(concat_2, WEIGHTS_HIDE_NETWORK['conv5x5_5'], BIASES_HIDE_NETWORK['conv5x5_5'])\n",
    "\n",
    "        concat_final = tf.concat([conv3x3, conv4x4, conv5x5], axis=3)\n",
    "\n",
    "        return conv2d(concat_final, WEIGHTS_HIDE_NETWORK['out'], BIASES_HIDE_NETWORK['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ntl41Jl4ImJp"
   },
   "outputs": [],
   "source": [
    "WEIGHTS_REVEAL_NETWORK = {\n",
    "    'conv3x3_1': tf.Variable(initializer([3, 3, 3, 50])),\n",
    "    'conv3x3_2': tf.Variable(initializer([3, 3, 50, 50])),\n",
    "    'conv3x3_3': tf.Variable(initializer([3, 3, 50, 50])),\n",
    "    'conv3x3_4': tf.Variable(initializer([3, 3, 50, 50])),\n",
    "\n",
    "    'conv4x4_1': tf.Variable(initializer([4, 4, 3, 50])),\n",
    "    'conv4x4_2': tf.Variable(initializer([4, 4, 50, 50])),\n",
    "    'conv4x4_3': tf.Variable(initializer([4, 4, 50, 50])),\n",
    "    'conv4x4_4': tf.Variable(initializer([4, 4, 50, 50])),\n",
    "\n",
    "    'conv5x5_1': tf.Variable(initializer([5, 5, 3, 50])),\n",
    "    'conv5x5_2': tf.Variable(initializer([5, 5, 50, 50])),\n",
    "    'conv5x5_3': tf.Variable(initializer([5, 5, 50, 50])),\n",
    "    'conv5x5_4': tf.Variable(initializer([5, 5, 50, 50])),\n",
    "\n",
    "    'conv3x3_5': tf.Variable(initializer([3, 3, 150, 50])),\n",
    "    'conv4x4_5': tf.Variable(initializer([4, 4, 150, 50])),\n",
    "    'conv5x5_5': tf.Variable(initializer([5, 5, 150, 50])),\n",
    "\n",
    "    'out': tf.Variable(initializer([1, 1, 150, 3])),\n",
    "}\n",
    "\n",
    "BIASES_REVEAL_NETWORK = {\n",
    "    'conv3x3_1': tf.Variable(tf.zeros([50])),\n",
    "    'conv3x3_2': tf.Variable(tf.zeros([50])),\n",
    "    'conv3x3_3': tf.Variable(tf.zeros([50])),\n",
    "    'conv3x3_4': tf.Variable(tf.zeros([50])),\n",
    "    \n",
    "    'conv4x4_1': tf.Variable(tf.zeros([50])),\n",
    "    'conv4x4_2': tf.Variable(tf.zeros([50])),\n",
    "    'conv4x4_3': tf.Variable(tf.zeros([50])),\n",
    "    'conv4x4_4': tf.Variable(tf.zeros([50])),\n",
    "\n",
    "    'conv5x5_1': tf.Variable(tf.zeros([50])),\n",
    "    'conv5x5_2': tf.Variable(tf.zeros([50])),\n",
    "    'conv5x5_3': tf.Variable(tf.zeros([50])),\n",
    "    'conv5x5_4': tf.Variable(tf.zeros([50])),\n",
    "\n",
    "\n",
    "    'conv3x3_5': tf.Variable(tf.zeros([50])),\n",
    "    'conv4x4_5': tf.Variable(tf.zeros([50])),\n",
    "    'conv5x5_5': tf.Variable(tf.zeros([50])),\n",
    "    \n",
    "    'out': tf.Variable(tf.zeros([3]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "All-WKWhImJq"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def reveal_network(hide_tensor):\n",
    "\n",
    "    hide_tensor = tf.reshape(hide_tensor, [-1, 64, 64, 3])\n",
    "    hide_tensor = tf.cast(hide_tensor, tf.float32)\n",
    "    hide_tensor = tf.math.divide(hide_tensor, 255.)\n",
    "\n",
    "    with tf.name_scope('reveal_network'):\n",
    "        with tf.name_scope('conv3x3'):\n",
    "            conv3x3 = hide_tensor\n",
    "            conv3x3 = conv2d(conv3x3, WEIGHTS_REVEAL_NETWORK['conv3x3_1'], BIASES_REVEAL_NETWORK['conv3x3_1'])\n",
    "            conv3x3 = conv2d(conv3x3, WEIGHTS_REVEAL_NETWORK['conv3x3_2'], BIASES_REVEAL_NETWORK['conv3x3_2'])\n",
    "            conv3x3 = conv2d(conv3x3, WEIGHTS_REVEAL_NETWORK['conv3x3_3'], BIASES_REVEAL_NETWORK['conv3x3_3'])\n",
    "            conv3x3 = conv2d(conv3x3, WEIGHTS_REVEAL_NETWORK['conv3x3_4'], BIASES_REVEAL_NETWORK['conv3x3_4'])\n",
    "\n",
    "        with tf.name_scope('conv4x4'):\n",
    "            conv4x4 = hide_tensor\n",
    "            conv4x4 = conv2d(conv4x4, WEIGHTS_REVEAL_NETWORK['conv4x4_1'], BIASES_REVEAL_NETWORK['conv4x4_1'])\n",
    "            conv4x4 = conv2d(conv4x4, WEIGHTS_REVEAL_NETWORK['conv4x4_2'], BIASES_REVEAL_NETWORK['conv4x4_2'])\n",
    "            conv4x4 = conv2d(conv4x4, WEIGHTS_REVEAL_NETWORK['conv4x4_3'], BIASES_REVEAL_NETWORK['conv4x4_3'])\n",
    "            conv4x4 = conv2d(conv4x4, WEIGHTS_REVEAL_NETWORK['conv4x4_4'], BIASES_REVEAL_NETWORK['conv4x4_4'])\n",
    "\n",
    "        with tf.name_scope('conv5x5'):\n",
    "            conv5x5 = hide_tensor\n",
    "            conv5x5 = conv2d(conv5x5, WEIGHTS_REVEAL_NETWORK['conv5x5_1'], BIASES_REVEAL_NETWORK['conv5x5_1'])\n",
    "            conv5x5 = conv2d(conv5x5, WEIGHTS_REVEAL_NETWORK['conv5x5_2'], BIASES_REVEAL_NETWORK['conv5x5_2'])\n",
    "            conv5x5 = conv2d(conv5x5, WEIGHTS_REVEAL_NETWORK['conv5x5_3'], BIASES_REVEAL_NETWORK['conv5x5_3'])\n",
    "            conv5x5 = conv2d(conv5x5, WEIGHTS_REVEAL_NETWORK['conv5x5_4'], BIASES_REVEAL_NETWORK['conv5x5_4'])\n",
    "        \n",
    "        concat_1 = tf.concat([conv3x3, conv4x4, conv5x5], axis=3)\n",
    "\n",
    "        conv3x3 = conv2d(concat_1, WEIGHTS_REVEAL_NETWORK['conv3x3_5'], BIASES_REVEAL_NETWORK['conv3x3_5'])\n",
    "        conv4x4 = conv2d(concat_1, WEIGHTS_REVEAL_NETWORK['conv4x4_5'], BIASES_REVEAL_NETWORK['conv4x4_5'])\n",
    "        conv5x5 = conv2d(concat_1, WEIGHTS_REVEAL_NETWORK['conv5x5_5'], BIASES_REVEAL_NETWORK['conv5x5_5'])\n",
    "\n",
    "        concat_final = tf.concat([conv3x3, conv4x4, conv5x5], axis=3)\n",
    "\n",
    "        return conv2d(concat_final, WEIGHTS_REVEAL_NETWORK['out'], BIASES_REVEAL_NETWORK['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "aQxTqNb2ImJr"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def steganorgraphy_loss(cover_input, secret_input, cover_output, secret_output, beta=1.0):\n",
    "    beta = tf.constant(beta, name=\"beta\")\n",
    "    \n",
    "    cover_mse = tf.losses.mean_squared_error(cover_input, cover_output)\n",
    "    secret_mse = tf.losses.mean_squared_error(secret_input, secret_output)\n",
    "    \n",
    "    total_loss = cover_mse + beta * secret_mse\n",
    "\n",
    "    return total_loss, cover_mse, secret_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "foneC4wrImJr"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajYvc18FImJs",
    "outputId": "f7fff4a7-4b9c-47cc-e48b-2fedffa1bbb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:\n",
      " Step 11/235:\n",
      "  Cover loss: 16626.6074\n",
      "  Secret loss 8931.0703\n",
      "  Total loss: 25557.6777.\n",
      "Seen so far: 352 samples\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for step, (cover, secret) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            prep_output = prep_network(secret)\n",
    "            hide_output = hide_network(cover, prep_output)\n",
    "            reveal_output = reveal_network(hide_output)\n",
    "            total_loss, cover_loss, secret_loss = steganorgraphy_loss(cover, secret, hide_output, reveal_output)\n",
    "        \n",
    "        trainable_variables = list(WEIGHTS_PREP_NETWORK.values()) + \\\n",
    "            list(WEIGHTS_HIDE_NETWORK.values()) + \\\n",
    "            list(WEIGHTS_REVEAL_NETWORK.values()) + \\\n",
    "            list(BIASES_PREP_NETWORK.values()) + \\\n",
    "            list(BIASES_HIDE_NETWORK.values ()) + \\\n",
    "            list(BIASES_REVEAL_NETWORK.values())\n",
    "        \n",
    "        grads = tape.gradient(total_loss, trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "\n",
    "        if (step % 10 == 0) or (step == STEPS - 1 == 0):\n",
    "            clear_output()\n",
    "            print(\n",
    "                \"Epoch %d/%d:\\n Step %d/%d:\\n  Cover loss: %.4f\\n  Secret loss %.4f\\n  Total loss: %.4f.\"\n",
    "                % (epoch + 1, EPOCHS, step + 1, STEPS, np.mean(cover_loss), np.mean(secret_loss), np.mean(total_loss))\n",
    "            )\n",
    "\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2f64sC9PWhaX"
   },
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAnGNbadUYnL"
   },
   "outputs": [],
   "source": [
    "loss_mean = list()\n",
    "\n",
    "for step, (cover, secret) in enumerate(test_dataset):\n",
    "    prep_output = prep_network(secret)\n",
    "    hide_output = hide_network(cover, prep_output)\n",
    "    reveal_output = reveal_network(hide_output)\n",
    "    total_loss, cover_loss, secret_loss = steganorgraphy_loss(cover, secret, hide_output, reveal_output)\n",
    "    \n",
    "    for loss in total_loss:\n",
    "        loss_mean.append(loss)\n",
    "\n",
    "    clear_output()\n",
    "    if (step % 10 == 0) or (step == STEPS - 1 == 0):\n",
    "      print(\"Secret image:\")\n",
    "      PIL.Image.fromarray(\n",
    "          np.array(secret[0], dtype=np.uint8), 'RGB'\n",
    "        ).show()\n",
    "      print(\"Cover image:\")\n",
    "      PIL.Image.fromarray(\n",
    "          np.array(cover[0], dtype=np.uint8), 'RGB'\n",
    "        ).show()\n",
    "\n",
    "\n",
    "      print(\"Secret revealed:\")\n",
    "      PIL.Image.fromarray(\n",
    "          np.array(reveal_output[0], dtype=np.uint8), 'RGB'\n",
    "        ).show()\n",
    "\n",
    "      print(\"Cover with secret:\")\n",
    "      PIL.Image.fromarray(\n",
    "          np.array(hide_output[0], dtype=np.uint8), 'RGB'\n",
    "        ).show()\n",
    "\n",
    "      \n",
    "    print(\"Total loss: %.4f\" % (np.mean(loss_mean)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
